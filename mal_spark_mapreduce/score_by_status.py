from pyspark.sql import SparkSession
from pyspark.sql.functions import avg

# ============================================
# 1Ô∏è‚É£ Kh·ªüi t·∫°o SparkSession
# ============================================
spark = SparkSession.builder \
    .appName("AnimeScoreByStatus") \
    .getOrCreate()

# ============================================
# 2Ô∏è‚É£ ƒê·ªçc file CSV t·ª´ HDFS (chu·∫©n ƒë·ªãnh d·∫°ng tab v√† quote)
# ============================================
df = spark.read \
    .option("inferSchema", "true") \
    .option("header", "false") \
    .option("sep", "\t") \
    .option("quote", '"') \
    .csv("hdfs:///user/hive/warehouse/mal_anime/part-m-00000")

# ============================================
# 3Ô∏è‚É£ G√°n t√™n c·ªôt ph√π h·ª£p
# ============================================
df = df.toDF(
    "mal_id", "title", "approved", "type", "episodes", "year", "season", "status",
    "score", "scored_by", "rank", "popularity", "members", "favorites",
    "genres", "studios", "demographics", "url"
)

# ============================================
# 4Ô∏è‚É£ T√≠nh trung b√¨nh ƒëi·ªÉm (score) theo tr·∫°ng th√°i ph√°t h√†nh (status)
# ============================================
avg_score_by_status = df.groupBy("status").agg(
    avg("score").alias("avg_score")
).orderBy("avg_score", ascending=False)

# ============================================
# 5Ô∏è‚É£ Hi·ªÉn th·ªã k·∫øt qu·∫£
# ============================================
print("=== üé¨ ƒêi·ªÉm trung b√¨nh theo tr·∫°ng th√°i ph√°t h√†nh (Status) ===")
avg_score_by_status.show(10, truncate=False)

# ============================================
# 6Ô∏è‚É£ Ghi k·∫øt qu·∫£ ra HDFS
# ============================================
avg_score_by_status.write \
    .option("header", "true") \
    .mode("overwrite") \
    .csv("hdfs:///user/hive/warehouse/output/status_avg_score")

# ============================================
# 7Ô∏è‚É£ D·ª´ng SparkSession
# ============================================
spark.stop()
