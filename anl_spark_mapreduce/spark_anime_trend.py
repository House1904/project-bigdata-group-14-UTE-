from pyspark.sql import SparkSession
from pyspark.sql.functions import col, count

# ============================================
# 1Ô∏è‚É£ Kh·ªüi t·∫°o SparkSession
# ============================================
spark = SparkSession.builder \
    .appName("AnimeTrendByYearSeason") \
    .getOrCreate()

# ============================================
# 2Ô∏è‚É£ ƒê·ªçc d·ªØ li·ªáu t·ª´ HDFS (ƒë·ªãnh d·∫°ng tab v√† quote)
# ============================================
input_path = "hdfs:///user/hive/warehouse/anl_anime/part-m-00000"

df = spark.read \
    .option("header", "false") \
    .option("inferSchema", "true") \
    .option("sep", "\t") \
    .option("quote", '"') \
    .csv(input_path)

# ============================================
# 3Ô∏è‚É£ G√°n t√™n c·ªôt (theo c·∫•u tr√∫c b·∫£ng AniList)
# ============================================
df = df.toDF(
    "id", "title_romaji", "title_english", "title_native", "format", "episodes",
    "duration", "source", "country", "isAdult", "score", "meanScore", "popularity",
    "favourites", "trending", "genres", "tags", "status", "studio", "season",
    "start_year", "url"
)

# ============================================
# 4Ô∏è‚É£ L·ªçc d·ªØ li·ªáu h·ª£p l·ªá (c√≥ start_year ho·∫∑c season)
# ============================================
df_year = df.filter(col("start_year").isNotNull())
df_season = df.filter(col("season").isNotNull())

# ============================================
# 5Ô∏è‚É£ ƒê·∫øm s·ªë l∆∞·ª£ng anime theo NƒÇM ph√°t h√†nh
# ============================================
anime_by_year = df_year.groupBy("start_year").agg(
    count("*").alias("anime_count")
).orderBy(col("start_year").asc())

# ============================================
# 6Ô∏è‚É£ ƒê·∫øm s·ªë l∆∞·ª£ng anime theo M√ôA ph√°t s√≥ng
# ============================================
anime_by_season = df_season.groupBy("season").agg(
    count("*").alias("anime_count")
).orderBy(col("anime_count").desc())

# ============================================
# 7Ô∏è‚É£ Ghi k·∫øt qu·∫£ ra HDFS
# ============================================
output_year = "hdfs:///user/hive/warehouse/output/anime_by_year"
output_season = "hdfs:///user/hive/warehouse/output/anime_by_season"

anime_by_year.write \
    .mode("overwrite") \
    .option("header", "true") \
    .csv(output_year)

anime_by_season.write \
    .mode("overwrite") \
    .option("header", "true") \
    .csv(output_season)

# ============================================
# 8Ô∏è‚É£ Hi·ªÉn th·ªã v√†i d√≤ng ki·ªÉm tra k·∫øt qu·∫£
# ============================================
print("=== üé¨ S·ªë l∆∞·ª£ng Anime theo NƒÉm ph√°t h√†nh ===")
anime_by_year.show(10, truncate=False)

print("=== üçÅ S·ªë l∆∞·ª£ng Anime theo M√πa ph√°t s√≥ng ===")
anime_by_season.show(10, truncate=False)

# ============================================
# 9Ô∏è‚É£ D·ª´ng SparkSession
# ============================================
spark.stop()
